{
    "dataset": "template",
    "dataloader": {
        "sequence_len": 200,
        "mlm_mask_prob": 0.15
    },
    "model": {
        "hidden_dim": 256,
        "num_heads": 4,
        "dropout_prob": 0.15
    },
    "train": {
        "epoch": 400,
        "patience": 200,
        "batch_size": 64,
        "optimizer": {
            "lr": 0.001
        }
    }
}
